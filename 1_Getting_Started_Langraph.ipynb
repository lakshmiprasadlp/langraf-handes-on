{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsFqqI3E8Xn4"
      },
      "source": [
        "## Chatbots With Langgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDGN7B1e8cX_",
        "outputId": "72a6b2d2-b5c0-4b21-fa0d-2d1bb4985267"
      },
      "outputs": [],
      "source": [
        "!pip install langgraph langsmith"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOSj_MR1AHBs",
        "outputId": "207a3ab4-0503-4b6b-fa24-d630d7cc66a8"
      },
      "outputs": [],
      "source": [
        "!pip install langchain langchain_groq langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgKIrwXJAjgA",
        "outputId": "7eec3700-d2d7-4ca3-bc2c-875c9cae1dd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "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\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "groq_api_key=userdata.get('groq_api_key')\n",
        "langsmith=userdata.get('LANGSMITH_API_KEY')\n",
        "print(langsmith)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFpKBPoZBQAa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = langsmith\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"]=\"CourseLanggraph\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJZl9uX-CFo7"
      },
      "outputs": [],
      "source": [
        "from langchain_groq import ChatGroq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9vOWf8yCJ4W",
        "outputId": "91931387-650d-4d7a-95de-31735c66ce27"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7efbfa765330>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7efbfa764670>, model_name='Gemma2-9b-It', groq_api_key=SecretStr('**********'))"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm=ChatGroq(groq_api_key=groq_api_key,model_name=\"Gemma2-9b-It\")\n",
        "llm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDc7RviFCVKB"
      },
      "source": [
        "## Start Building Chatbot Using Langgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPcSBey6CUeF"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph,START,END\n",
        "from langgraph.graph.message import add_messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVzn-8rrC6-7"
      },
      "outputs": [],
      "source": [
        "class State(TypedDict):\n",
        "  # Messages have the type \"list\". The `add_messages` function\n",
        "    # in the annotation defines how this state key should be updated\n",
        "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
        "  messages:Annotated[list,add_messages]\n",
        "\n",
        "graph_builder=StateGraph(State)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgjwX6BQDcfk",
        "outputId": "10f24dc5-6242-454b-b61c-cfecf260ae22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7efbfa91fee0>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph_builder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOF74t5GDeJO"
      },
      "outputs": [],
      "source": [
        "def chatbot(state:State):\n",
        "  return {\"messages\":llm.invoke(state['messages'])}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-m7NDe74EPGW"
      },
      "outputs": [],
      "source": [
        "graph_builder.add_node(\"chatbot\",chatbot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKFbmbqcEVIq",
        "outputId": "9f91e0af-022e-4485-8151-db69c5cc3ccb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7efbfa91fee0>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph_builder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jBWX44IEWy-"
      },
      "outputs": [],
      "source": [
        "graph_builder.add_edge(START,\"chatbot\")\n",
        "graph_builder.add_edge(\"chatbot\",END)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PN4O63shEtyZ"
      },
      "outputs": [],
      "source": [
        "graph=graph_builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "_PPER3gfEygm",
        "outputId": "fbe87a93-4e15-47e7-9cc3-5cebe43ce64f"
      },
      "outputs": [
        {
          "data": {
            "image/jpeg": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "try:\n",
        "  display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDvjUFmxFCwU",
        "outputId": "c77c0d85-b6f5-4dee-81c5-5c728019aaed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User: hello\n",
            "dict_values([{'messages': AIMessage(content='Hello! ðŸ‘‹  How can I help you today? ðŸ˜Š\\n', response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 15, 'total_tokens': 30, 'completion_time': 0.028948375, 'prompt_time': 0.00232277, 'queue_time': None, 'total_time': 0.031271145}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-7c991b84-1ff6-461a-baa7-08c8d2767d10-0', usage_metadata={'input_tokens': 15, 'output_tokens': 15, 'total_tokens': 30})}])\n",
            "content='Hello! ðŸ‘‹  How can I help you today? ðŸ˜Š\\n' response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 15, 'total_tokens': 30, 'completion_time': 0.028948375, 'prompt_time': 0.00232277, 'queue_time': None, 'total_time': 0.031271145}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run-7c991b84-1ff6-461a-baa7-08c8d2767d10-0' usage_metadata={'input_tokens': 15, 'output_tokens': 15, 'total_tokens': 30}\n",
            "Assistant: Hello! ðŸ‘‹  How can I help you today? ðŸ˜Š\n",
            "\n",
            "User: what is generative ai\n",
            "dict_values([{'messages': AIMessage(content=\"Generative AI is a type of artificial intelligence that focuses on creating new content. \\n\\nThink of it like this: instead of simply analyzing existing data, generative AI learns the underlying patterns and structures within that data and then uses that knowledge to generate entirely new outputs.\\n\\nHere's a breakdown:\\n\\n**What it does:**\\n\\n* **Creates new content:** This can include text, images, audio, video, code, and even 3D models.\\n\\n* **Learns from existing data:**  It's trained on massive datasets to understand the nuances and rules of the content it's designed to generate.\\n\\n* **Generates variations:** It can create different variations of a given prompt or input, offering options and exploring creative possibilities.\\n\\n**Examples:**\\n\\n* **Text Generation:**\\n\\nChatGPT (like me!), writing stories, poems, articles, dialogue\\n\\n* **Image Generation:**\\n\\nDALL-E 2, Midjourney creating realistic or imaginative images from text descriptions\\n\\n* **Audio Generation:**\\n\\nJukebox, Amper Music composing music in various styles\\n\\n* **Code Generation:**\\n\\nGitHub Copilot assisting developers in writing code\\n\\n**How it works:**\\n\\nGenerative AI often relies on deep learning algorithms, particularly a type called generative adversarial networks (GANs). These algorithms consist of two neural networks that work in tandem:\\n\\n* **Generator:** Creates new content.\\n* **Discriminator:** Evaluates the quality of the generated content and tries to distinguish it from real data.\\n\\nThrough this competitive process, the generator improves its ability to produce increasingly realistic and sophisticated outputs.\\n\\n**Applications:**\\n\\nGenerative AI has a wide range of potential applications, including:\\n\\n* **Creative Arts:** Writing, music composition, art generation\\n* **Design:** Creating prototypes, generating marketing materials\\n* **Entertainment:** Developing interactive stories, generating game assets\\n* **Research:** Exploring new scientific concepts, simulating experiments\\n* **Education:** Personalized learning experiences, creating interactive learning materials\\n\\n**Ethical Considerations:**\\n\\nWhile generative AI offers exciting possibilities, it also raises ethical concerns:\\n\\n* **Misinformation:** Potential for creating realistic fake news, deepfakes, and propaganda.\\n* **Bias:** AI models can inherit and amplify biases present in the training data, leading to unfair or discriminatory outputs.\\n* **Copyright:** Questions surrounding the ownership and copyright of AI-generated content.\\n\\n\\n\\n\\nLet me know if you have any more questions about generative AI!\\n\", response_metadata={'token_usage': {'completion_tokens': 501, 'prompt_tokens': 18, 'total_tokens': 519, 'completion_time': 1.044149282, 'prompt_time': 0.002699907, 'queue_time': None, 'total_time': 1.046849189}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-6b200b57-a482-45f9-a07c-4fa92c425157-0', usage_metadata={'input_tokens': 18, 'output_tokens': 501, 'total_tokens': 519})}])\n",
            "content=\"Generative AI is a type of artificial intelligence that focuses on creating new content. \\n\\nThink of it like this: instead of simply analyzing existing data, generative AI learns the underlying patterns and structures within that data and then uses that knowledge to generate entirely new outputs.\\n\\nHere's a breakdown:\\n\\n**What it does:**\\n\\n* **Creates new content:** This can include text, images, audio, video, code, and even 3D models.\\n\\n* **Learns from existing data:**  It's trained on massive datasets to understand the nuances and rules of the content it's designed to generate.\\n\\n* **Generates variations:** It can create different variations of a given prompt or input, offering options and exploring creative possibilities.\\n\\n**Examples:**\\n\\n* **Text Generation:**\\n\\nChatGPT (like me!), writing stories, poems, articles, dialogue\\n\\n* **Image Generation:**\\n\\nDALL-E 2, Midjourney creating realistic or imaginative images from text descriptions\\n\\n* **Audio Generation:**\\n\\nJukebox, Amper Music composing music in various styles\\n\\n* **Code Generation:**\\n\\nGitHub Copilot assisting developers in writing code\\n\\n**How it works:**\\n\\nGenerative AI often relies on deep learning algorithms, particularly a type called generative adversarial networks (GANs). These algorithms consist of two neural networks that work in tandem:\\n\\n* **Generator:** Creates new content.\\n* **Discriminator:** Evaluates the quality of the generated content and tries to distinguish it from real data.\\n\\nThrough this competitive process, the generator improves its ability to produce increasingly realistic and sophisticated outputs.\\n\\n**Applications:**\\n\\nGenerative AI has a wide range of potential applications, including:\\n\\n* **Creative Arts:** Writing, music composition, art generation\\n* **Design:** Creating prototypes, generating marketing materials\\n* **Entertainment:** Developing interactive stories, generating game assets\\n* **Research:** Exploring new scientific concepts, simulating experiments\\n* **Education:** Personalized learning experiences, creating interactive learning materials\\n\\n**Ethical Considerations:**\\n\\nWhile generative AI offers exciting possibilities, it also raises ethical concerns:\\n\\n* **Misinformation:** Potential for creating realistic fake news, deepfakes, and propaganda.\\n* **Bias:** AI models can inherit and amplify biases present in the training data, leading to unfair or discriminatory outputs.\\n* **Copyright:** Questions surrounding the ownership and copyright of AI-generated content.\\n\\n\\n\\n\\nLet me know if you have any more questions about generative AI!\\n\" response_metadata={'token_usage': {'completion_tokens': 501, 'prompt_tokens': 18, 'total_tokens': 519, 'completion_time': 1.044149282, 'prompt_time': 0.002699907, 'queue_time': None, 'total_time': 1.046849189}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run-6b200b57-a482-45f9-a07c-4fa92c425157-0' usage_metadata={'input_tokens': 18, 'output_tokens': 501, 'total_tokens': 519}\n",
            "Assistant: Generative AI is a type of artificial intelligence that focuses on creating new content. \n",
            "\n",
            "Think of it like this: instead of simply analyzing existing data, generative AI learns the underlying patterns and structures within that data and then uses that knowledge to generate entirely new outputs.\n",
            "\n",
            "Here's a breakdown:\n",
            "\n",
            "**What it does:**\n",
            "\n",
            "* **Creates new content:** This can include text, images, audio, video, code, and even 3D models.\n",
            "\n",
            "* **Learns from existing data:**  It's trained on massive datasets to understand the nuances and rules of the content it's designed to generate.\n",
            "\n",
            "* **Generates variations:** It can create different variations of a given prompt or input, offering options and exploring creative possibilities.\n",
            "\n",
            "**Examples:**\n",
            "\n",
            "* **Text Generation:**\n",
            "\n",
            "ChatGPT (like me!), writing stories, poems, articles, dialogue\n",
            "\n",
            "* **Image Generation:**\n",
            "\n",
            "DALL-E 2, Midjourney creating realistic or imaginative images from text descriptions\n",
            "\n",
            "* **Audio Generation:**\n",
            "\n",
            "Jukebox, Amper Music composing music in various styles\n",
            "\n",
            "* **Code Generation:**\n",
            "\n",
            "GitHub Copilot assisting developers in writing code\n",
            "\n",
            "**How it works:**\n",
            "\n",
            "Generative AI often relies on deep learning algorithms, particularly a type called generative adversarial networks (GANs). These algorithms consist of two neural networks that work in tandem:\n",
            "\n",
            "* **Generator:** Creates new content.\n",
            "* **Discriminator:** Evaluates the quality of the generated content and tries to distinguish it from real data.\n",
            "\n",
            "Through this competitive process, the generator improves its ability to produce increasingly realistic and sophisticated outputs.\n",
            "\n",
            "**Applications:**\n",
            "\n",
            "Generative AI has a wide range of potential applications, including:\n",
            "\n",
            "* **Creative Arts:** Writing, music composition, art generation\n",
            "* **Design:** Creating prototypes, generating marketing materials\n",
            "* **Entertainment:** Developing interactive stories, generating game assets\n",
            "* **Research:** Exploring new scientific concepts, simulating experiments\n",
            "* **Education:** Personalized learning experiences, creating interactive learning materials\n",
            "\n",
            "**Ethical Considerations:**\n",
            "\n",
            "While generative AI offers exciting possibilities, it also raises ethical concerns:\n",
            "\n",
            "* **Misinformation:** Potential for creating realistic fake news, deepfakes, and propaganda.\n",
            "* **Bias:** AI models can inherit and amplify biases present in the training data, leading to unfair or discriminatory outputs.\n",
            "* **Copyright:** Questions surrounding the ownership and copyright of AI-generated content.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Let me know if you have any more questions about generative AI!\n",
            "\n",
            "User: q\n",
            "Good Bye\n"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "  user_input=input(\"User: \")\n",
        "  if user_input.lower() in [\"quit\",\"q\"]:\n",
        "    print(\"Good Bye\")\n",
        "    break\n",
        "  for event in graph.stream({'messages':(\"user\",user_input)}):\n",
        "    print(event.values())\n",
        "    for value in event.values():\n",
        "      print(value['messages'])\n",
        "      print(\"Assistant:\",value[\"messages\"].content)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
